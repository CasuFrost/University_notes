\documentclass[10pt, letterpaper]{report}
% !TeX program = xelatex
%==================PREAMBOLO=======================%
\input{../../../preamble/preamble.tex}
\usepackage{algorithm}
\usepackage{algpseudocode}
 %TOGLI COMMENTO SE USI XELATEX
%\usepackage{fontspec}
\title{Ottimizzazione} %========TITOLO========%
\author{Marco Casu}
\date{\vspace{-5ex}}
\begin{document}

%==================COPERTINA=======================%
\begin{titlepage}
    
\begin{center}
    %TOGLI COMMENTO SE USI XELATEX
   %\setmainfont{Palace Script MT}
   \HUGE Marco Casu\acc
    %\setmainfont{Grand Casino}
     %TOGLI COMMENTO SE USI XELATEX
    %\setmainfont{h Halfroad}
    \HUGE \decothreeleft\hphantom{ }{\HUGE\selectfont Ottimizzazione}\hphantom{ }\decothreeright
     %TOGLI COMMENTO SE USI XELATEX
   % \setmainfont{Times New Roman}
\end{center}
\thispagestyle{empty}
\begin{figure}[h]
    \centering{
        %l'immagine deve avere una risoluzione 2048x2048
        \includegraphics[width=1\textwidth ]{images/Copertina.jpeg}
    }
\end{figure}
\vfill 
\centering \includegraphics[width=0.4\textwidth ]{../../../preamble/Stemma_sapienza.png} \acc
\centering \Large \color{sapienza}Facoltà di Ingegneria dell'Informazione,
Informatica e Statistica\\
Dipartimento di Informatica
\end{titlepage}

%===================FINE COPERTINA======================%
\newpage
%\pagecolor{cartaRiciclata}%\setmainfont{Algerian}
\Large
Questo documento è distribuito sotto la licenza 
\color{blue}\href{https://www.gnu.org/licenses/fdl-1.3.txt}{GNU}\color{black},  
è un resoconto degli appunti (eventualmente integrati con libri di testo) tratti dalle lezioni del corso di Ottimizzazione
\hphantom{a}per la laurea 
triennale in Informatica. Se dovessi notare errori, ti prego di segnalarmeli.
\vfill
\begin{figure}[h!]
    \raggedright
    \includegraphics[width=0.4\textwidth,right ]{../../../preamble/tomodachi.pdf} 
\end{figure}
\newpage %\setmainfont{Times New Roman}
\normalsize
\newtheorem{definizione}{Definizione}
\newtheorem{teorema}{Teorema}
\newtheorem{lemma2}{Lemma}
\newtheorem{proposizione}{Proposizione}
\newtheorem{osservazione}{Osservazione}

\tableofcontents 
\newpage

%==================FOOTER e HEADER=======================%
\fancyhf{}
\fancyhead[L]{\nouppercase{\leftmark}}
\fancyhead[R]{Sezione \thesection}
\fancyfoot[C]{\thepage}
\fancyfoot[L]{Appunti di Ottimizzazione}
\fancyfoot[R]{ Marco Casu}
%\fancyfoot[R]{\setmainfont{Palace Script MT}\huge Marco Casu \setmainfont{Times New Roman}}
%==================FOOTER e HEADER=======================%

%Ricorda del comando \flowerLine per separare le sottosezioni. Le sezioni si separano nelle diverse pagine

%==================INIZIO======================%
\chapter{Flussi nei Grafi}
\section{Definizione e Grafo Residuo}
\begin{definizione}
    Una \textbf{network} o \textbf{rete} $G=(V,E,c,s,t)$ è un particolare grafo diretto, in cui $V$ ed $E$ sono i vertici e gli archi, tali per cui è soddisfatta la condizione 
    $$\forall (u,v)\in E(G), \ \ \ \exists (v,u)\in E(G) $$
    $c:E(G)\rightarrow\R^+$ è una funzione detta \textbf{capacità}, $s$ e $t$ sono due particolari vertici in $V(G)$ denominati \textbf{source} e \textbf{sink}.
\end{definizione}
\begin{definizione}
    Data una network $G=(V,E,c,s,t)$, un \textbf{flusso} per $G$ è una funzione $f:E(G)\rightarrow\R$ tale per cui valgono le seguenti\begin{enumerate}
        \item \textg{skew-simmetria} : $f(u,v)=-f(v,u), \ \ \forall (u,v)\in E(G)$ 
        \item \textg{capacità rispettata} : $f(u,v)\le c(u,v), \ \ \forall (u,v)\in E(G)$ 
        \item \textg{conservatività del flusso} : $\displaystyle\sum_{(u,v)\in E(G)}f(u,v)=0, \ \ \forall v\in V(G)\backslash\{s,t\}$ 
    \end{enumerate}
\end{definizione}
Denominiamo flusso uscente dal vertice $v$ la somma del flusso (positivo) valutato su tutti gli archi che hanno $v$ come primo membro (che collegano $v$ ad un'altro vertice). Analogamente (ma in maniera opposta) si definisce il flusso entrante.
Dato un flusso $f$ per una network $G$ si definisce il \textbf{valore del flusso} la somma del flusso uscente da $s$ 
$$ \text{val}(f)=\sum_{(s,u)\in E(G)}f(s.u)$$
La terza proprietà, di conservazione del flusso, asserisce che il flusso uscente da un nodo deve essere identico al flusso entrante, sia $x$ un vertice fissato in $V(G)$
$$ \sum_{\begin{matrix}(u,x)\in E(G)\\f(u,x)>0\end{matrix}}f(u,x)=-\Bigg(
\sum_{\begin{matrix}(x,u)\in E(G)\\f(x,u)<0\end{matrix}}f(x,u)\Bigg)$$
\begin{definizione}
    Sia $G=(V,E,c,s,t)$ una network e $f$ un flusso per $G$, il \textbf{grafo residuo} è il grafo diretto $G'$ definito come segue\begin{itemize}
        \item $\forall v\in V(G), \ \ v\in V(G')$
        \item $(u,v)\in E(G)\land f(u,v)<c(u,v)\implies (u,v)\in E(G')$
    \end{itemize}
    Inoltre è definita una funzione $r:E(G')\rightarrow \R^+$ detta \textbf{capacità residua} definita come segue $$ r(u,v)=c(u,v)-f(u,v)$$
\end{definizione}
\begin{figure}[h!]
    \centering 
    \includegraphics[width=0.7\textwidth ]{images/residual_graph.eps}
    \caption{Capacità residua del flusso (evidenziato in rosso)}
\end{figure}
Si assuma che esiste un cammino $P$ in $G'$ da $s$ a $t$, si consideri il residuo minimo valutato sugli archi contenuti nel cammino 
$$ \alpha=\min_{(u,v)\in E(P)}r(u,v)$$
Si definisce una funzione $f':E(G)\rightarrow\R$ come segue $$ f'(u,v)=\begin{cases}
    f(u,v)+\alpha  \ \text{ se } \ (u,v)\in E(P) \\
    f(u,v)-\alpha  \ \text{ se } \ (v,u) \in E(P)\\
    f(u,v)  \ \text{ altrimenti } 
\end{cases}$$
\begin{proposizione}\label{prop:augmentation}
$f'$ è un flusso per $G$.
\end{proposizione}
\textit{Dimostrazione} : Sia $(u,v)$ un arco in $G$, se $(u,v)\notin E(P)$, allora $f'(u,v)=f(u,v)$ e conseguentemente $f'(v,u)=f'(v,u)$, quindi la proprietà di skew simmetria è preservata. Differentemente, se $(u,v)\in E(P)$ si avrebbe che $f'(u,v)=f(u,v)+\alpha$ e $f'(v,u)=f(v,u)-\alpha=-f(u,v)-\alpha=-(f(u,v)+\alpha)$, quindi il nuovo flusso rispetta la proprietà di skew-simmetria. 

Per ogni arco $(u,v)\in E(P)$ si ha che $f'(u,v)=f(u,v)+\alpha$, $\alpha$ è (per definizione) minore o uguale a $r(u,v)$ quindi 
$$ f'(u,v)\le f(u,v)+r(u,v)$$
Ma essendo che $f(u,v)+r(u,v)=c(u,v)$, $f'$ rispetta la capacità.

Se $x\notin V(P)$ si avrebbe che $f'(x,u)=f(x,u)$ per ogni $u$ adiacente ad $x$, allora $$ \sum_{(x,u)\in E(G)}f(x,u)=0$$
Assumendo che $x\in V(P)$,  vi è un arco uscente da $x$ il cui flusso è aumentato di $\alpha$, vi è quindi (per definizione di $f'$) un'arco entrante in $x$ il cui flusso è diminuito di $\alpha$, quindi è ancora vero che
$$ \sum_{\begin{matrix}(u,x)\in E(G)\\f'(u,x)>0\end{matrix}}f'(u,x)=-\Bigg(
\sum_{\begin{matrix}(x,u)\in E(G)\\f'(x,u)<0\end{matrix}}f'(x,u)\Bigg)$$
la proprietà di conservazione del flusso è rispettata.\hfill$\blacksquare$\bigskip 

Il valore del nuovo flusso è uguale al valore del flusso di partenza aumentato di $\alpha$ 
$$ \text{val}(f')=\text{val}(f)+\alpha$$
Dato che un singolo arco $(s,u)$ per qualche $u$ è necessariamente presente nel cammino $P$ da $s$ a $t$, ed il valore di $f'$ su $(s,u)$ è stato aumentato di $\alpha$.
La proposizione \ref{prop:augmentation} delinea una procedura per la ricerca di un flusso ottimale (di valore massimo) per una network.
\begin{algorithm}
    \caption{Ford–Fulkerson}\label{alg:Ford–Fulkerson}
    \begin{algorithmic}
    \Require network $G=(V,E,c,s,t)$
    \State si definisce un flusso $f$ tale che $f(u,v)=0$, $\forall (u,v)\in E(G)$
    \State si definisce il grafo residuo $G'$ dato il flusso $f$
    \While{Esiste un cammino $P$ in $G'$ da $s$ a $t$}
    \State si definisce la funzione delle capacità residue $r:E(G')\rightarrow \R$
    \State $\displaystyle\alpha=\min_{(u,v)\in E(P)}r(u,v)$
    \State Si definisce un flusso $f'=f$
    \For{$(u,v)\in E(P)$}
    \State $f'(u,v)=f(u,v)+\alpha$
    \State $f'(v,u)=f(v,u)-\alpha$
    \EndFor
    \EndWhile
    \end{algorithmic}
    \end{algorithm}
Alla fine dell'esecuzione, il flusso $f'$ sarà ottimale per la network data.
\begin{osservazione}
Se le capacità della network sono numeri interi, l'algoritmo termina. Se invece le capacità sono numeri reali, l'algoritmo potrebbe non terminare.
\end{osservazione}
\section{Tagli $s-t$}
Data una network  $G=(V,E,c,s,t)$, ed un flusso $f$ per $G$, si consideri un'insieme $\mathcal U\subset V(G)$ tale che 
\begin{itemize}
    \item $s\in \mathcal U$
    \item $t\notin \mathcal U$
\end{itemize}
Tale insieme è detto \textbf{insieme di taglio}, si consideri ora il flusso uscente dai vertici presenti in $\mathcal U$
$$\sum_{\begin{matrix}
    (u,x)\in E(G)\\ \text{t.c. }u\in \mathcal U
\end{matrix}}f(u,x)$$
Per la proprietà di conservazione del flusso si ha che il flusso uscente da ogni vertice diverso da $s$ è nullo, ed il flusso uscente dal vertice $s$ è il valore del flusso.
$$\sum_{\begin{matrix}
    (u,x)\in E(G)\\ \text{t.c. }u\in \mathcal U
\end{matrix}}f(u,x)=\sum_{(s,x)\in E(G)}f(s,x)=\text{val}(f)$$
La sommatoria a sinistra può essere riscritta come la somma del flusso uscente dai vertici in $\mathcal U$ verso i vertici in $\mathcal U$, e del flusso uscente dai vertici in $\mathcal U$ verso i vertici che non sono contenuti in $\mathcal U$
$$ \sum_{\begin{matrix}
    (u,x)\in E(G)\\ \text{t.c. }u\in \mathcal U
\end{matrix}}f(u,x)=
\sum_{\begin{matrix}
    (u,x)\in E(G)\\ \text{t.c. }u,x\in \mathcal U
\end{matrix}}f(u,x)+\sum_{\begin{matrix}
    (u,x)\in E(G)\\ \text{t.c. }u\in \mathcal U\\ x\notin \mathcal U
\end{matrix}}f(u,x)$$
Per la proprietà di skew-simmetria il flusso uscente dai vertici in $\mathcal U$ verso i vertici in $\mathcal U$ è nullo 
$$ \sum_{\begin{matrix}
    (u,x)\in E(G)\\ \text{t.c. }u\in \mathcal U
\end{matrix}}f(u,x)=\sum_{\begin{matrix}
    (u,x)\in E(G)\\ \text{t.c. }u\in \mathcal U\\ x\notin \mathcal U
\end{matrix}}f(u,x)$$
\textbf{Conclusione} : Il valore di $f$ è uguale alla somma dei flussi uscenti dai vertici in $\mathcal U$ verso i vertici non contenuti in $\mathcal U$. Questa proprietà è invariante rispetto la scelta di $\mathcal U$, a patto che rispetti le proprietà inizialmente elencate (deve contenere $s$ ma non $t$). 

\begin{definizione}
    si definisce \textbf{capacità di taglio} la somma delle capacità degli archi che collegano i vertici in $\mathcal U$ ai vertici in $V(G)\backslash \mathcal U$
    $$c_t= \sum_{\begin{matrix}
        (u,x)\in E(G),\\u\in \mathcal U,\\ x\notin \mathcal U
    \end{matrix}}c(u,x)$$
\end{definizione}
\begin{figure}[h!]
    \centering 
    \includegraphics[width=0.5\textwidth ]{images/capacità_di_taglio.eps}
\end{figure}
\begin{osservazione}
    il valore massimale del flusso è limitato dalla capacità di taglio 
    $$ \text{val}(f)\le c_t$$
\end{osservazione}
\begin{proposizione} \label{prop:insTaglio}
Data una network $G$, se esiste un flusso $f^*$ ed un'insieme di taglio $\mathcal U$ tali che $$\text{val}(f)= \sum_{\begin{matrix}
    (u,x)\in E(G),\\u\in \mathcal U,\\ x\notin \mathcal U
\end{matrix}}c(u,x)$$
ossia, il valore del flusso è identico alla capacità di taglio, allora $f^*$ è un flusso ottimale.
\end{proposizione}
L'algoritmo di Ford-Fulkerson restituisce un flusso ottimale $f^*$, da questo è possibile individuare l'insieme di taglio $\mathcal U$ associato, in particolare, se $G^*$ è il grafo residuo della network rispetto il flusso dato in output $f^*$, allora l'insieme di taglio sarà composto da tutti i nodi raggiungibili da $s$ in $G^*$, chiaramente, fra questi non vi sarà $t$, data la definizione dell'algoritmo, che termina proprio quando non vi è un cammino da $s$ a $t$.\bigskip 

Si consideri adesso una network $G$, di cui $f^*$ è il flusso ottimale trovato tramite l'algoritmo \ref{alg:Ford–Fulkerson}. Sia $\mathcal U$ l'insieme di taglio dato dai nodi raggiungibili da $s$ nel grafo residuo $G^*$.
\begin{osservazione}
    Per ogni arco $(x,y)\in E(G)$ con $x\in \mathcal U$ e $y\notin \mathcal U$, si avrà che $$ f^*(x,y)=c(x,y)$$
\end{osservazione}
Il valore del flusso è uguale alla somma delle capacità degli archi che collegano i vertici in $\mathcal U$ a quelli fuori da $\mathcal U$
$$ \sum_{\begin{matrix}
    (x,y)\in E(G)\\ x\in \mathcal U\\ y\notin \mathcal U
\end{matrix}}f^*(x,y)=\sum_{\begin{matrix}
    (x,y)\in E(G)\\ x\in \mathcal U\\ y\notin \mathcal U
\end{matrix}}c(x,y)=\text{val}(f^*)$$
La proposizione \ref{prop:insTaglio} non implica che non ci possa essere una network il cui flusso ottimale a valore strettamente minore della capacità di taglio di uno specifico insieme $\mathcal U$, si consideri l'immagine in figura \ref{taglio2}, in cui è applicata la notazione sugli archi \textit{capacità/flusso}, la capacità di taglio è data dalla somma delle capacità sugli archi evidenziati, ed è uguale a 4, nonostante questo, il flusso ottimale per la network in questione ha valore 1.
\begin{figure}[h!]
    \centering 
    \includegraphics[width=0.6\textwidth ]{images/capacità_di_taglio_2.eps}
    \caption{network con taglio sui vertici}
    \label{taglio2}
\end{figure}

Nonostante ciò, esiste sempre un insieme $\mathcal U$ contenente $s$ e non $t$ la cui capacità di taglio è uguale al valore del flusso ottimale per la network data, tale insieme può essere trovato adoperando l'algoritmo di Ford-Fulkerson nella procedura precedentemente elencata.
\begin{osservazione}
    L'algoritmo di Ford-Fulkerson, termina sempre se le capacità della network sono numeri in $\mathbb Q$.
\end{osservazione}
\textit{Dimostrazione} : Se le capacità $c_i$ sono numeri razionali allora esiste esiste un numero naturale $N\in\N$ tale che ogni capacità è della forma $c_i=\frac{a_i}{N}$, ad ogni iterazione dell'algoritmo il valore del flusso aumenta di almeno $\frac{1}{N}$, quindi in un numero finito di passi raggiungerà il valore ottimale.\hfill$\blacksquare$
\section{Percorso Minimo nell'Aumento del Flusso}
Durante la computazione dell'algoritmo di Ford-Fulkerson, viene scelto un qualsiasi percorso che connetta $s$ a $t$ nel grafo residuo, tale scelta comporta un aumento del valore del flusso, ma una scelta differente di percorso potrebbe far si che l'aumento in quella iterazione sia maggiore, e che il numero finale di iterazioni per trovare il flusso ottimale sia minore.
Il seguente esempio mostra l'inefficienza dell'algoritmo \ref{alg:Ford–Fulkerson}, si consideri la  network in figura \ref{network2M} (alcuni archi sono stati omessi).
\begin{figure}[h!]
    \centering 
    \includegraphics[width=0.35\textwidth ]{images/network2M.eps}
    \caption{Sugli archi sono indicate le capacità}
    \label{network2M}
\end{figure}
Il flusso massimale ha valore $2M$, nonostante  ciò, se ad ogni iterazione dell'algoritmo venisse selezionato il percorso $s\rightarrow a \rightarrow b \rightarrow t$, allora l'aumento del valore sarebbe uguale ad uno, e sarebbero necessarie $2M$ iterazioni, differentemente, la scelta del percorso $s\rightarrow a \rightarrow t$ implicherebbe già solo alla prima iterazione un'aumento pari ad $M$.

La complessità computazionale in questo caso dipende linearmente da $M$, tale valore è però codificato in binario (occupando $\log M$ spazio), quindi l'algoritmo di Ford-Fulkerson è esponenziale nelle dimensioni dell'input. È possibile considerare una rivisitazione dell'algoritmo \ref{alg:Ford–Fulkerson}, in cui ad ogni iterazione viene selezionato il percorso più breve (minor numero di archi) da $s$ a $t$ nel grafo residuo. Tale algoritmo rivisitato è noto con il nome di \textbf{Edmonds-Karp}.
\begin{algorithm}
    \caption{Edmonds-Karp}\label{alg:Edmonds-Karp}
    \begin{algorithmic}
    \Require network $G=(V,E,c,s,t)$
    \State si definisce un flusso $f$ tale che $f(u,v)=0$, $\forall (u,v)\in E(G)$
    \State si definisce il grafo residuo $G'$ dato il flusso $f$
    \While{Esiste un cammino $P$ in $G'$ da $s$ a $t$}
    \State $P=$ cammino più breve da $s$ a $t$ in $G'$ 
    \State si definisce la funzione delle capacità residue $r:E(G')\rightarrow \R$
    \State $\displaystyle\alpha=\min_{(u,v)\in E(P)}r(u,v)$
    \State Si definisce un flusso $f'=f$
    \For{$(u,v)\in E(P)$}
    \State $f'(u,v)=f(u,v)+\alpha$
    \State $f'(v,u)=f(v,u)-\alpha$
    \EndFor
    \EndWhile
    \end{algorithmic}
    \end{algorithm}
\begin{osservazione}
    Se $G$ è un grafo diretto e $P$ è il percorso più breve fra due vertici $x$ ed $y$, allora $\forall z \in V(P)$, si ha che il sotto cammino $x\rightarrow z$ in $P$ è anch'esso un percorso più breve.
\end{osservazione}
\begin{proposizione}\label{monotoningIncreasing}
    Sia $G=(V,E,c,s,t)$ una network. Sia $G_i$ il grafo residuo all'$i$-esima iterazione dell'algoritmo \ref{alg:Edmonds-Karp}, e $G_{i'}$ il grafo residuo all'$i'$-esima iterazione, con $i'>i$, allora
    \begin{equation} \text{dist}_{G_i}(s,u)\le \text{dist}_{G_{i'}}(s,u)\end{equation}
    La distanza dal vertice source $s$ rispetto ogni altro vertice aumenta in maniera monotona ad ogni passo dell'algoritmo.
\end{proposizione}
\textit{Dimostrazione} : Supponiamo che esiste un nodo $v\in G$ tale che  
$ \text{dist}_{G_i}(s,v)>\text{dist}_{G_{i'}}(s,v)$, si assume inoltre che la distanza $\text{dist}_{G_{i'}}(s,v)$ sia la più piccola possibile ($v$ è il nodo più vicino ad $s$ in $G_{i'}$). Sia $w$ il penultimo vertice del cammino $P'=u_1,u_2\dots u_k$ in $G_{i'}$, con $u_1=s$ e $u_k=v$.
\begin{figure}[h!]
    \centering 
    \includegraphics[width=0.35\textwidth ]{images/Edmond-Karp-Proof.eps}
\end{figure}
Ne segue che  
\begin{equation}\label{eq:EdKarp}
\text{dist}_{G_i}(s,v)>\text{dist}_{G_{i'}}(s,v)=\text{dist}_{G_{i'}}(s,w)+1\ge  \text{dist}_{G_i}(s,w)+1\end{equation}
\textbf{Nota } : 
nella dimostrazione si sta assumendo che la proposizione non sia valida per il nodo $v$, ma che sia valida per il nodo $w$, da qui è verificata la disuguaglianza a destra nell'equazione \ref{eq:EdKarp}.

Ciò implica che l'arco $(w,v)$ è presente in $G_{i'}$ ma non in $G_i$, se così non fosse sarebbe vero che $\text{dist}_{G_{i'}}(s,w)\ge  \text{dist}_{G_i}(s,w)+1$, e quindi  $w=u_i$ e $v=u_{i-1}$ per qualche $i$, ma questa è una contraddizione dato che $v$ segue $w$ nel cammino $P'$, quindi l'asserto è verificato.\hfill$\blacksquare$
\begin{teorema}\label{nm-aumenti}
Nell'algoritmo di Edmonds-Karp, applicato su una network $G$, il numero totale di incrementi del valore del flusso è al più $n\cdot m$, con $n=|V(G)|$ e $m=|E(G)|$. Tale affermazione è valida anche se le capacità sugli archi sono numeri reali.
\end{teorema}
\textit{Dimostrazione} : Sia $G_i$ il grafo residuo nell'$i$-esima iterazione dell'algoritmo \ref{alg:Edmonds-Karp}, analogamente, sia $f_i$ il flusso valutato anch'esso durante l'$i$-esima iterazione. Chiaramente $G_0=G$ e $f_0(e)=0, \ \forall e$. 
\begin{definizione}
    Durante l'esecuzione dell'algoritmo \ref{alg:Edmonds-Karp}, un'arco $(u,v)$ è detto \textbf{critico} in $i$ se \begin{itemize}
        \item $(u,v)\in G_i$
        \item $(u,v)\notin G_{i+1}$
    \end{itemize}
\end{definizione}
Se $P_i$ è il percorso minimo da $s$ a $t$ considerato nell'$i$-esima iterazione, e $(u,v)$ è critico in $i$, per definizione dell'algoritmo si ha che $(u,v)\in E(P_i)$.\begin{quote}
    \begin{lemma2}
    Sia $(u,v)$ un'arco di una network $G$, durante l'esecuzione dell'algoritmo \ref{alg:Edmonds-Karp}, l'arco $(u,v)$ può essere considerato critico al più $\frac{n}{2}$ volte.
    \end{lemma2}
    \textit{Dimostrazione Lemma} : Siano 
    $$\pi(1)<\pi(2)<\dots < \pi(L) $$
    gli indici delle iterazioni in cui $(u,v)$ è critico, con $L\le \frac{n}{2}$, chiaramente $$(u,v)\in E(P_{\pi(i)}) $$
    per qualche $1\le i \le L$. Chiaramente
    $$\text{dist}_{G_{\pi(i)}}(s,v) = 
    \text{dist}_{G_{\pi(i)}}(s,u)+1 $$
    Se $(u,v)$ è critico in $\pi(i)$ ed in $\pi(i+1)$, allora deve esistere un iterazione $i'$ compresa fra queste 
    $$\pi(i)<i'<\pi(i+1) $$
    In cui l'arco $(u,v)$ è stato re-inserito nel grafo residuo, quindi il flusso su $(u,v)$ in tale iterazione è diminuito, necessariamente (per skew-simmetria) il flusso su $(v,u)$ è aumentato, quindi quest'ultimo arco si trovava sul percorso da $s$ a $t$ nell'iterazione $i'$.
    $$ (v,u)\in E(P_{i'})$$
    Date le precedenti osservazioni, si deducono le seguenti disuguaglianze 
    \begin{align}
        \text{dist}_{G_{i'}}(s,u)= \text{dist}_{G_{i'}}(s,v)+1\\
        \text{dist}_{G_{i'}}(s,v)+1\ge 
        \text{dist}_{G_{\pi(i)}}(s,v)+1 \\ 
        \text{dist}_{G_{\pi(i)}}(s,v)+1 =\text{dist}_{G_{\pi(i)}}(s,u)+2 \\ 
         \Downarrow   \\ 
          \text{dist}_{G_{\pi(i+1)}}(s,u)\ge
          \text{dist}_{G_{\pi(i)}}(s,u)+2
    \end{align}
    Essendo che la distanza fra due vertici è limitata da $n=|V(G)|$, si ha che 
    $$\text{dist}_{G_{\pi(i)}}(s,u)\le n-1 $$
\begin{itemize}
    \item la distanza fra $s$ ed $u$ è al più $n-1$ 
    \item la distanza fra $s$ ed $u$ aumenta almeno di due in due iterazioni differenti in cui $(u,v)$ è critico
\end{itemize}
La conclusione è che non possono esistere più di $\frac{n}{2}$ indici $\pi(i)$ in cui $(u,v)$ è critico. \hfill$\square$
\end{quote}
La dimostrazione del teorema \ref{nm-aumenti} segue in maniera naturale, ad ogni iterazione un'arco è critico, essendo che ci sono $m$ archi ed ognuno può essere critico al più $\frac{n}{2}$ volte, il numero  totale di aumenti del flusso è al più $\frac{1}{2}nm$. \hfill$\blacksquare$ 
\section{Cammini Edge-Disjoint in un Grafo}
In questa sezione verrà esposta un'applicazione dell'algoritmo di ricerca del flusso massimo. Sia $G$ un grafo non diretto, si definisce la \textit{network associata} a $G$, il grafo diretto $\vec G$ tale che\begin{itemize}
    \item $u\in V(G)\implies u\in V(\vec G)$
    \item $(u,v)\in E(G)\implies \begin{cases}
        (u,v)\in E(\vec G)\\ 
        (v,u)\in E(\vec G)
    \end{cases}$
    \item $\forall (u,v)\in \vec G$ \ \ \ , $c(u,v)=1$
\end{itemize}
\begin{figure}[h!]
    \centering 
    \includegraphics[width=0.65\textwidth ]{images/networkAssociata.eps}
\end{figure}
Si può anche risalire in maniera naturale ad un grafo non diretto associato ad una network.
\begin{definizione}
    Dato un grafo non diretto $G$ e due nodi $s,t$, un'insieme di cammini da $s$ a $t$ è \textbf{edge-disjoint} se non condividono alcun arco.
\end{definizione}
Verrà mostrato come, dato un grafo $G$, il numero massimo di cammini edge-disjoint è uguale al valore del flusso ottimale nella network associata.
\begin{definizione}
    Dato un flusso $f$ per una network $\vec G$, si definisce \textbf{supporto del flusso} l'insieme $$W=\{(u,v)\in E(\vec G) \text{ t.c. }f(u,v)\ne 0\} $$
\end{definizione}
\begin{proposizione}
    Se nel supporto $W$ di un flusso $f$ per una network $\vec G$ gli archi compongono $k$ cammini diretti da $s$ a $t$, allora ci sono $k$ cammini edge-disjoint da $s$ a $t$ nel grafo non diretto associato.
\end{proposizione}
\textit{Dimostrazione} : \redText{TODO : continuare}





\chapter{Programmazione Lineare}
\section{Insiemi Convessi}
La programmazione lineare consiste nella ricerca di un vettore (ingresso di una funzione lineare) in cui tale funzione assume il valore massimo, all'interno di un dominio definito da un'insieme di vincoli lineari. La funzione da massimizzare è detta \textbf{funzione obiettivo}, un'esempio di programma lineare può essere il seguente 
$$ x_1+x_2$$
soggetto ai vincoli 
$$ \begin{matrix}
    x_1\ge 0 \\ 
    x_2 \ge 0 \\ 
    x_2-x_1\le 1 \\ 
    x_1+6x_2\le 15 \\ 
    4x_1-x_2\le 10
\end{matrix}$$
Un punto è \textbf{ammissibile} se soddisfa tutti i vincoli lineari.
L'insieme di punti ammissibili si può rappresentare su un piano in questo caso, essendo un sotto-insieme di $\R^2$.
\begin{figure}[h]
    \centering{
        \includegraphics[width=0.4\textwidth ]{images/LP_esempio1.pdf}
        \caption{Insieme dei punti ammissibili}
        \label{LP_esempio1}
    }
\end{figure}
La funzione obiettivo essendo lineare si può rappresentare come prodotto scalare fra due vettori $\mathbf c$ e $\mathbf x$ 
$$\mathbf c^T\mathbf x=\begin{bmatrix}
    1&1
\end{bmatrix}\begin{bmatrix}
    x_1\\ x_2
\end{bmatrix} =x_1+x_2$$
Può risultare utile rappresentare sul piano anche il vettore $\mathbf c$ e la retta equivalente al sottospazio $$\text{span}(\mathbf c)=\{\alpha \mathbf c \ | \ \alpha \in \R\}$$
\begin{figure}[h]
    \centering{
        \includegraphics[width=0.4\textwidth ]{images/LP_esempio2.pdf}
    }
\end{figure}
Si consideri una retta $y'$ perpendicolare alla retta definita da $\text{span}(\mathbf c)$, i punti di $y'$ che intersecano l'insieme delle soluzioni ammissibili condividono la stessa immagine se valutati sulla funzione obiettivo. Un'interpretazione geometrica del problema può essere la seguente\begin{quotation}
    Massimizzare la funzione obiettivo equivale a trovare il massimo $\beta$ tale che l'iperpiano definito da $\mathbf c^T\mathbf x = \beta$ perpendicolare alla retta $\alpha \mathbf c$ interseca l'insieme dei punti ammissibili.
\end{quotation}
Si definisce \textbf{soluzione ottimale} ogni soluzione ammissibile che massimizza la funzione obiettivo.
\begin{figure}[h]
    \centering{
        \includegraphics[width=0.4\textwidth ]{images/LP_esempio3.pdf}
    }
    \caption{Il punto $(3,2)$ è una soluzione ottimale per il programma lineare}
        \label{LP_esempio3}
\end{figure}
Il numero di soluzioni di un programma lineare può variare fra i seguenti casi\begin{enumerate}
    \item Vi è un'unica soluzione ottimale.
    \item Vi sono infinite soluzioni ottimale.
    \item Non ci sono soluzioni ammissibili, nessun punto soddisfa tutti i vincoli lineari.
    \item Non ci sono soluzioni ottimali perché il problema non è limitato, ciò avviene se l'insieme dei punti ammissibili non è chiuso.
\end{enumerate}
Generalmente la funzione obiettivo  $f:\R^n\rightarrow \R$ è del tipo 
$$c_1x_1+c_2x_2+\dots+c_nx_n $$
e gli $m$ vincoli sono della forma $$\begin{matrix}
    a_{11}x_1+a_{21}x_2+\dots + a_{n1}x_2\le b_1\\ 
    a_{12}x_1+a_{22}x_2+\dots + a_{n2}x_2\le b_2\\ \vdots \\ 
    a_{1m}x_1+a_{2m}x_2+\dots + a_{nm}x_2\le b_m
\end{matrix}$$
\begin{osservazione}
    Massimizzare  $\mathbf c^T \mathbf x$ equivale a minimizzare $\mathbf -\mathbf c^T\mathbf x $.
\end{osservazione}
Si può quindi assumere che un generico problema di programmazione lineare riguardi la massimizzazione di una funzione del tipo $\mathbf c^T \mathbf x$ per un fissato $\mathbf c \in \R^n$. Inoltre, ogni vincolo del tipo 
\begin{equation}\label{vincolo} a_{1i}x_1+a_{2i}x_2+\dots + a_{ni}x_2\le b_i\end{equation}
è soddisfatto dagli stessi punti che soddisfano 
$$ -a_{1i}x_1-a_{2i}x_2-\dots - a_{ni}x_2\ge b_i $$
Quindi si può assumere che ogni vincolo sia scritto nella forma \ref{vincolo}. Inoltre ogni vincolo di uguaglianza equivale a due disuguaglianze. Date le precedenti osservazioni, si può definire un'insieme di $m$ vincoli in maniera compatta tramite una matrice $m\times n $ ed un vettore $\mathbf b\in \R^m$. 
$$ A\mathbf x \le \mathbf b$$ 
Inoltre ogni vincolo di positività del tipo $x_i\ge 0$ equivale ad il vincolo $-x_i\le 0$. Se in un programma lineare una variabile $x_i$ può assumere qualsiasi valore in $\R$, si può sostituire con la differenza di due nuove variabili 
$$x_i=z_i-z_i' $$
ed imporre i vincoli $$ z_i,z_i'\ge 0$$ 
in tal modo è possibile, per ogni variabile del programma lineare, imporre la positività. Ciò è utile per definire una \textit{forma standard} per un programma lineare. 
\begin{definizione}
    Un programma lineare in \textbf{forma standard} è un problema di ottimizzazione del tipo 
\end{definizione}
    $$
    \begin{matrix}
        \text{max } \ \mathbf c^T\mathbf x\\ 
        A\mathbf x \le \mathbf b\\ 
        \mathbf x \ge 0
    \end{matrix}
    $$
Dove 
$$ 
\begin{matrix}
    \mathbf x,\mathbf c\in \R^n\\ 
    A \in \text{Mat}(m\times n)\\ 
    \mathbf b\in \R^m
\end{matrix}
$$
L'esistenza di soluzioni ammissibili dipende esclusivamente dalla matrice $A$. È impossibile che un programma lineare abbia un numero finito di soluzioni diverso da 0 e 1. In seguito verrà dimostrato che se un programma lineare ha due punti ammissibili che sono soluzione, allora ha infinite soluzioni.
\begin{definizione}
    Dati due punti $\mathbf x,\mathbf y \in \R^n$, si definisce \textbf{segmento di linea} fra i punti l'insieme \end{definizione} 
    $$ \{\alpha\mathbf x +(1-\alpha)\mathbf y \text{ t.c. }\alpha \in [0,1] \}$$
\begin{definizione}
    Un sotto-insieme $X\subseteq \R^n$ è \textbf{convesso} se la seguente è verificata 
\end{definizione}
$$\forall \mathbf x,\mathbf y \in X, \ \ \  
\{\alpha\mathbf x +(1-\alpha)\mathbf y \text{ t.c. }\alpha \in [0,1] \}\subseteq X
$$
\begin{figure}[h]
    \centering{
        \includegraphics[width=0.7\textwidth ]{images/insiemeConvesso.eps}
    }
\end{figure}
\begin{proposizione}
    L'insieme dei punti ammissibili di un programma lineare è convesso.
\end{proposizione}
\textit{Dimostrazione} : Siano $\mathbf x,\mathbf y\in \R^n$ due punti ammissibili, sia $\alpha\in[0,1]$ fissato, si considera il punto (appartenente al segmento) 
$$\alpha\mathbf x +(1-\alpha)\mathbf y $$ 
si ha che \begin{eqnarray}
    A(\alpha\mathbf x +(1-\alpha)\mathbf y)=\\ 
    \alpha A \mathbf x + (1-\alpha)A\mathbf y = \\ 
    \alpha \mathbf b + (1-\alpha )\mathbf b = \mathbf b 
\end{eqnarray}
quindi Il punto soddisfa gli $m$ vincoli
$$A(\alpha\mathbf x +(1-\alpha)\mathbf y)\le \mathbf b $$
Inoltre essendo che 
$$ \alpha \ge 0, \mathbf x \ge 0, \mathbf y \ge 0$$
si ha che 
$$ \alpha\mathbf x +(1-\alpha)\mathbf y\ge 0$$
Quindi $\alpha\mathbf x +(1-\alpha)\mathbf y$ soddisfa tutti i vincoli del programma lineare, ed appartiene quindi ai punti ammissibili.
\hfill$\blacksquare$
\begin{proposizione}
    Se un programma lineare in forma standard ha due soluzioni ottimali $\mathbf x^*,\mathbf y^*\in \R^n$, allora ne ha infinite.
\end{proposizione}
\textit{Dimostrazione} : Sia $ \mathbf z$ un punto sul segmento delineato da $\mathbf x^*,\mathbf y^*$
$$\mathbf z = \alpha\mathbf x^* +(1-\alpha)\mathbf y^* \ \ \text{ per qualche }\alpha \in [0,1] $$
si ha che 
 \begin{eqnarray}
    \mathbf c^T \mathbf z = \\
    \mathbf c^T(\alpha\mathbf x^*  +(1-\alpha)\mathbf y^*)=\\
    \alpha\mathbf c^T\mathbf x^*  +(1-\alpha)\mathbf c^T\mathbf y^*
\end{eqnarray}
Essendo che $\mathbf x^*$ e $\mathbf y^*$ sono entrambe soluzioni ottimali, si ha che $c^T\mathbf x^*=c^T\mathbf y^*$
\begin{eqnarray}
    \alpha\mathbf c^T\mathbf x^*  +(1-\alpha)\mathbf c^T\mathbf y^*=\\ 
    \alpha\mathbf c^T\mathbf x^*  +(1-\alpha)\mathbf c^T\mathbf x^*=
    c^T\mathbf x^*
\end{eqnarray}
Quindi anche $\mathbf z$ è soluzione, essendo che quest'ultimo è un generico punto sul segmento, tutti i punti del segmento sono soluzioni.\hfill$\blacksquare$
\section{Applicazioni della Programmazione Lineare}











\end{document}
\begin{proposizione}
    Sia $\vec G = (V,E,c,s,t)$ una network tale per cui $c(e)=1,\ \forall e\in E(\vec G)$. Se esiste un flusso $f$ di valore $k$ per $\vec G$, allora il grafo non diretto associato $G$ ha $k$ cammini edge-disjoint da $s$ a $t$.
\end{proposizione}

